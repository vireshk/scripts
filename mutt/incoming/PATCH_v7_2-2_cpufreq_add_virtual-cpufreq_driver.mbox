From vireshk  Tue Oct  1 08:45:18 2024
Delivered-To: viresh.kumar@linaro.org
Received: from pop.gmail.com [142.251.175.108] 	by vireshk-i7 with POP3 (fetchmail-6.4.2) 	for <vireshk@localhost> (single-drop); Tue, 01 Oct 2024 08:45:18 +0530 (IST)
Received: by 2002:a05:7208:c243:b0:8b:2085:db5e with SMTP id w3csp1027283rbd;         Wed, 18 Sep 2024 17:09:45 -0700 (PDT)
X-Forwarded-Encrypted: i=2; AJvYcCX6dehexEq+q0J7FW/E2ksWn3UZtJGc5zuAv/hzxPIQa/HNKmDVeuNbNWs5CFDs/1VlvG4FK5g6c+fgc0E=@linaro.org
X-Received: by 2002:a05:690c:113:b0:6c9:9341:1ce1 with SMTP id 00721157ae682-6dbb6b89530mr205216417b3.32.1726704584921;         Wed, 18 Sep 2024 17:09:44 -0700 (PDT)
ARC-Seal: i=1; a=rsa-sha256; t=1726704584; cv=none;         d=google.com; s=arc-20240605;         b=EscnaTtdpGyK3gv348wDTZJffecOKKvh/M4wJ5ANkFVoRLi81AUQUG9C3YzfmrFCZP          o2jvP2SqGcSF/c00iFriLpw25i2T6TJHAWSkSDgupVFs+ym1LpNYIntxfVi6IRmq78mI          T2CMV5/XnqxOrwciwAnsHQR3vejCWdPxARfiqHgrTpgFkHEKzF6A0mlYyqmGlQk7arIN          H7VuP4lsNsWgHFJQ9NvydrS+TgIwCSY+rnxZnxEenfRKvyTKoJ/rQHREDHSTT9iV5lo6          TuvvWa4VEgYBGg1DdLlo37I5/P5Ez6QmxJFMskAz1Crxj1ASICpayg7uUYHmMHOWN77N          7UVg==
ARC-Message-Signature: i=1; a=rsa-sha256; c=relaxed/relaxed; d=google.com; s=arc-20240605;         h=cc:to:from:subject:message-id:references:mime-version:in-reply-to          :date:dkim-signature;         bh=GyeWfaiZCQZsvQ2lfnNsmw4OSqkGRzb2PVV/qLrwcGY=;         fh=TOpbPK8s25fTpSAXP0DGct3tBrViJE/3Su0JUl8fdt0=;         b=X6TIfb1wqg2OqaOByOjbYN8Vwwsarq1cCHfU53tn5f7uVw4RGYyRNJsuss2drHTvo4          +e6KzzNHjqSPKMRWIE7HObIYFaNro2WKc441znM0I7Ki1twhxp8eKb1hewGydBns+skm          bOxLM0KWUxyZpixXSWYnacET/d09leHf+K9/+XdBkFGJsoqJk7gxrFvErh3Ky18lMtP/          6mWlypOTYOjMraHZw+YTSKA+PLd5F6zUi0dpFMgWuzjkBtWH7dML5n9qhX+HvUwSgOhM          Z8/8jSFgRlhoODyw+5nWIUF7fRjr7O/mhmVuSOKDJxa1OlK2qlc3P0iMi5Xe7+G1wZvf          ozIw==;         dara=google.com
ARC-Authentication-Results: i=1; mx.google.com;        dkim=pass header.i=@google.com header.s=20230601 header.b=hMH2HDrr;        spf=pass (google.com: domain of 3ygvrzgckdisspaxspxv33v0t.r31ax6t7w.z91p60x2p63.36v@flex--davidai.bounces.google.com designates 209.85.220.73 as permitted sender) smtp.mailfrom=3yGvrZgcKDIsspAxspxv33v0t.r31Ax6t7w.z91p60x2p63.36v@flex--davidai.bounces.google.com;        dmarc=pass (p=REJECT sp=REJECT dis=NONE) header.from=google.com;        dara=neutral header.i=@linaro.org
Return-Path: <3yGvrZgcKDIsspAxspxv33v0t.r31Ax6t7w.z91p60x2p63.36v@flex--davidai.bounces.google.com>
Received: from mail-sor-f73.google.com (mail-sor-f73.google.com. [209.85.220.73])         by mx.google.com with SMTPS id 00721157ae682-6de095114casor5069837b3.7.2024.09.18.17.09.44         for <viresh.kumar@linaro.org>         (Google Transport Security);         Wed, 18 Sep 2024 17:09:44 -0700 (PDT)
Received-SPF: pass (google.com: domain of 3ygvrzgckdisspaxspxv33v0t.r31ax6t7w.z91p60x2p63.36v@flex--davidai.bounces.google.com designates 209.85.220.73 as permitted sender) client-ip=209.85.220.73;
Authentication-Results: mx.google.com;        dkim=pass header.i=@google.com header.s=20230601 header.b=hMH2HDrr;        spf=pass (google.com: domain of 3ygvrzgckdisspaxspxv33v0t.r31ax6t7w.z91p60x2p63.36v@flex--davidai.bounces.google.com designates 209.85.220.73 as permitted sender) smtp.mailfrom=3yGvrZgcKDIsspAxspxv33v0t.r31Ax6t7w.z91p60x2p63.36v@flex--davidai.bounces.google.com;        dmarc=pass (p=REJECT sp=REJECT dis=NONE) header.from=google.com;        dara=neutral header.i=@linaro.org
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;         d=google.com; s=20230601; t=1726704584; x=1727309384; darn=linaro.org;         h=cc:to:from:subject:message-id:references:mime-version:in-reply-to          :date:from:to:cc:subject:date:message-id:reply-to;         bh=GyeWfaiZCQZsvQ2lfnNsmw4OSqkGRzb2PVV/qLrwcGY=;         b=hMH2HDrricO57xElZ/jkyYScUUGV00PAkOiimh3E46+kgzFTY9S9MpHCzLeWVVGqp8          WC8WRG9KJFi+lJ32cz3ljwN/D3MPWTy10xrSRjwbgHAgzZPsQTeIKuaGi8dHhGj0MnAs          PXbD1LbdDdfh9uRnyIBUyY6zf7oXvvqrpTgsgX/oAsRQGM1t0pgy2D0cC5oZ5GcTM2ak          5xCWr2BAKEG5uER8W0RlRP7OzTQHNpBqKXw/OJem3CoSXBYTJMmAjuRx6D8ibVvKbfVZ          QHf1/aZomdrKpA3f8G/KAnXkcc6DTBWeEYbA0RWO5fbyM+eyLLhquozh/eEpqAXR9RtJ          zrlg==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;         d=1e100.net; s=20230601; t=1726704584; x=1727309384;         h=cc:to:from:subject:message-id:references:mime-version:in-reply-to          :date:x-gm-message-state:from:to:cc:subject:date:message-id:reply-to;         bh=GyeWfaiZCQZsvQ2lfnNsmw4OSqkGRzb2PVV/qLrwcGY=;         b=E/R+DPrAglgtXjiPuC9UbkO/Tx5Xf4FuN7UlRMm/C199SJla9165Draubc6gHKM2bE          Cm54rfrN2sb/rjbPoWbQKXMN+vpJdC4UvyQenKd03PmFPXggvA/JaO7HmRZrXkyysYvD          j5igQqg0p4tHAlMfA4Kwh/uey68MgMVNEOuOCAh7ndIjb/KUcu1dzJRHTFJvCI//EQNX          xbizhHPqWFt2IXYcixDPjIJ+vwwhClf7/Lugk2tvTZ1MA8C7oMQe5jPMnVpPHV3hewc/          awv1Qxgm1MVyoI3k6OjeQjWIRBZmBduYm/UvhF1aYLNmHQ8uz5Ug2EQXdE4VfY8ARc0q          g1ng==
X-Forwarded-Encrypted: i=1; AJvYcCVEfAELK30FJ26QKHZNCTNZ7rAieJTo4UPzHrIgapIotWGlqzTnxH1y3Cpf1NrTzRMdh5qzhG5B7DzX76U=@linaro.org
X-Gm-Message-State: AOJu0YxcrpdSzzmebflqq1aE4V3pig/JibBJl4VfMAsGNiiWjiUtuaZD 	Rci0GApOgny/xA05znWzAdZ/I9xRu7FIM55nLymPw2wN/jWL0VIP990HyZ3aooSzW8BzzIcNr5w 	ZRxytYQ==
X-Google-Smtp-Source: AGHT+IEY/FNsRrRJTJ+HfHn8qvlFPkR9pW+FUYun3rukwsKXSFgqA5etJcQjY0zi7Cy+rUFBYaQUIAIs7Qtl
X-Received: from davidai2.mtv.corp.google.com ([2620:15c:211:201:2985:f9c1:f5a3:ad7a])  (user=davidai job=sendgmr) by 2002:a81:b80f:0:b0:6be:523:af53 with SMTP id  00721157ae682-6de09880f96mr175377b3.3.1726704584345; Wed, 18 Sep 2024  17:09:44 -0700 (PDT)
Date: Wed, 18 Sep 2024 17:08:33 -0700
In-Reply-To: <20240919000837.1004642-1-davidai@google.com>
Mime-Version: 1.0
References: <20240919000837.1004642-1-davidai@google.com>
X-Mailer: git-send-email 2.46.0.792.g87dc391469-goog
Message-ID: <20240919000837.1004642-3-davidai@google.com>
Subject: [PATCH v7 2/2] cpufreq: add virtual-cpufreq driver
From: David Dai <davidai@google.com>
To: "Rafael J. Wysocki" <rafael@kernel.org>, Viresh Kumar <viresh.kumar@linaro.org>,  	Rob Herring <robh@kernel.org>, Krzysztof Kozlowski <krzk+dt@kernel.org>, Conor Dooley <conor+dt@kernel.org>,  	Sudeep Holla <sudeep.holla@arm.com>, David Dai <davidai@google.com>,  	Saravana Kannan <saravanak@google.com>
Cc: Quentin Perret <qperret@google.com>, Masami Hiramatsu <mhiramat@google.com>,  	Will Deacon <will@kernel.org>, Peter Zijlstra <peterz@infradead.org>,  	Vincent Guittot <vincent.guittot@linaro.org>, Marc Zyngier <maz@kernel.org>,  	Oliver Upton <oliver.upton@linux.dev>, Dietmar Eggemann <dietmar.eggemann@arm.com>,  	Pavan Kondeti <quic_pkondeti@quicinc.com>, Gupta Pankaj <pankaj.gupta@amd.com>,  	Mel Gorman <mgorman@suse.de>, kernel-team@android.com, linux-pm@vger.kernel.org,  	devicetree@vger.kernel.org, linux-kernel@vger.kernel.org
Content-Type: text/plain; charset="UTF-8"
Status: RO
Content-Length: 13593
Lines: 414

Introduce a virtualized cpufreq driver for guest kernels to improve
performance and power of workloads within VMs.

This driver does two main things:

1. Sends the frequency of vCPUs as a hint to the host. The host uses the
hint to schedule the vCPU threads and decide physical CPU frequency.

2. If a VM does not support a virtualized FIE(like AMUs), it queries the
host CPU frequency by reading a MMIO region of a virtual cpufreq device
to update the guest's frequency scaling factor periodically. This enables
accurate Per-Entity Load Tracking for tasks running in the guest.

Co-developed-by: Saravana Kannan <saravanak@google.com>
Signed-off-by: Saravana Kannan <saravanak@google.com>
Signed-off-by: David Dai <davidai@google.com>
---
 drivers/cpufreq/Kconfig           |  14 ++
 drivers/cpufreq/Makefile          |   1 +
 drivers/cpufreq/virtual-cpufreq.c | 333 ++++++++++++++++++++++++++++++
 include/linux/arch_topology.h     |   1 +
 4 files changed, 349 insertions(+)
 create mode 100644 drivers/cpufreq/virtual-cpufreq.c

diff --git a/drivers/cpufreq/Kconfig b/drivers/cpufreq/Kconfig
index 2561b215432a..92a83a9bb2e1 100644
--- a/drivers/cpufreq/Kconfig
+++ b/drivers/cpufreq/Kconfig
@@ -217,6 +217,20 @@ config CPUFREQ_DT
 
 	  If in doubt, say N.
 
+config CPUFREQ_VIRT
+	tristate "Virtual cpufreq driver"
+	depends on GENERIC_ARCH_TOPOLOGY
+	help
+	  This adds a virtualized cpufreq driver for guest kernels that
+	  read/writes to a MMIO region for a virtualized cpufreq device to
+	  communicate with the host. It sends performance requests to the host
+	  which gets used as a hint to schedule vCPU threads and select CPU
+	  frequency. If a VM does not support a virtualized FIE such as AMUs,
+	  it updates the frequency scaling factor by polling host CPU frequency
+	  to enable accurate Per-Entity Load Tracking for tasks running in the guest.
+
+	  If in doubt, say N.
+
 config CPUFREQ_DT_PLATDEV
 	tristate "Generic DT based cpufreq platdev driver"
 	depends on OF
diff --git a/drivers/cpufreq/Makefile b/drivers/cpufreq/Makefile
index 0f184031dd12..10d7d6e55da8 100644
--- a/drivers/cpufreq/Makefile
+++ b/drivers/cpufreq/Makefile
@@ -16,6 +16,7 @@ obj-$(CONFIG_CPU_FREQ_GOV_ATTR_SET)	+= cpufreq_governor_attr_set.o
 
 obj-$(CONFIG_CPUFREQ_DT)		+= cpufreq-dt.o
 obj-$(CONFIG_CPUFREQ_DT_PLATDEV)	+= cpufreq-dt-platdev.o
+obj-$(CONFIG_CPUFREQ_VIRT)		+= virtual-cpufreq.o
 
 # Traces
 CFLAGS_amd-pstate-trace.o               := -I$(src)
diff --git a/drivers/cpufreq/virtual-cpufreq.c b/drivers/cpufreq/virtual-cpufreq.c
new file mode 100644
index 000000000000..a050b3a6737f
--- /dev/null
+++ b/drivers/cpufreq/virtual-cpufreq.c
@@ -0,0 +1,333 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (C) 2024 Google LLC
+ */
+
+#include <linux/arch_topology.h>
+#include <linux/cpufreq.h>
+#include <linux/init.h>
+#include <linux/sched.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/of_address.h>
+#include <linux/of_platform.h>
+#include <linux/platform_device.h>
+#include <linux/slab.h>
+
+/*
+ * CPU0..CPUn
+ * +-------------+-------------------------------+--------+-------+
+ * | Register    | Description                   | Offset |   Len |
+ * +-------------+-------------------------------+--------+-------+
+ * | cur_perf    | read this register to get     |    0x0 |   0x4 |
+ * |             | the current perf (integer val |        |       |
+ * |             | representing perf relative to |        |       |
+ * |             | max performance)              |        |       |
+ * |             | that vCPU is running at       |        |       |
+ * +-------------+-------------------------------+--------+-------+
+ * | set_perf    | write to this register to set |    0x4 |   0x4 |
+ * |             | perf value of the vCPU        |        |       |
+ * +-------------+-------------------------------+--------+-------+
+ * | perftbl_len | number of entries in perf     |    0x8 |   0x4 |
+ * |             | table. A single entry in the  |        |       |
+ * |             | perf table denotes no table   |        |       |
+ * |             | and the entry contains        |        |       |
+ * |             | the maximum perf value        |        |       |
+ * |             | that this vCPU supports.      |        |       |
+ * |             | The guest can request any     |        |       |
+ * |             | value between 1 and max perf  |        |       |
+ * |             | when perftbls are not used.   |        |       |
+ * +---------------------------------------------+--------+-------+
+ * | perftbl_sel | write to this register to     |    0xc |   0x4 |
+ * |             | select perf table entry to    |        |       |
+ * |             | read from                     |        |       |
+ * +---------------------------------------------+--------+-------+
+ * | perftbl_rd  | read this register to get     |   0x10 |   0x4 |
+ * |             | perf value of the selected    |        |       |
+ * |             | entry based on perftbl_sel    |        |       |
+ * +---------------------------------------------+--------+-------+
+ * | perf_domain | performance domain number     |   0x14 |   0x4 |
+ * |             | that this vCPU belongs to.    |        |       |
+ * |             | vCPUs sharing the same perf   |        |       |
+ * |             | domain number are part of the |        |       |
+ * |             | same performance domain.      |        |       |
+ * +-------------+-------------------------------+--------+-------+
+ */
+
+#define REG_CUR_PERF_STATE_OFFSET 0x0
+#define REG_SET_PERF_STATE_OFFSET 0x4
+#define REG_PERFTBL_LEN_OFFSET 0x8
+#define REG_PERFTBL_SEL_OFFSET 0xc
+#define REG_PERFTBL_RD_OFFSET 0x10
+#define REG_PERF_DOMAIN_OFFSET 0x14
+#define PER_CPU_OFFSET 0x1000
+
+#define PERFTBL_MAX_ENTRIES 64U
+
+static void __iomem *base;
+static DEFINE_PER_CPU(u32, perftbl_num_entries);
+
+static void virt_scale_freq_tick(void)
+{
+	int cpu = smp_processor_id();
+	u32 max_freq = (u32)cpufreq_get_hw_max_freq(cpu);
+	u64 cur_freq;
+	unsigned long scale;
+
+	cur_freq = (u64)readl_relaxed(base + cpu * PER_CPU_OFFSET
+			+ REG_CUR_PERF_STATE_OFFSET);
+
+	cur_freq <<= SCHED_CAPACITY_SHIFT;
+	scale = (unsigned long)div_u64(cur_freq, max_freq);
+	scale = min(scale, SCHED_CAPACITY_SCALE);
+
+	this_cpu_write(arch_freq_scale, scale);
+}
+
+static struct scale_freq_data virt_sfd = {
+	.source = SCALE_FREQ_SOURCE_VIRT,
+	.set_freq_scale = virt_scale_freq_tick,
+};
+
+static unsigned int virt_cpufreq_set_perf(struct cpufreq_policy *policy,
+					  unsigned int target_freq)
+{
+	writel_relaxed(target_freq,
+		       base + policy->cpu * PER_CPU_OFFSET + REG_SET_PERF_STATE_OFFSET);
+	return 0;
+}
+
+static unsigned int virt_cpufreq_fast_switch(struct cpufreq_policy *policy,
+					     unsigned int target_freq)
+{
+	virt_cpufreq_set_perf(policy, target_freq);
+	return target_freq;
+}
+
+static u32 virt_cpufreq_get_perftbl_entry(int cpu, u32 idx)
+{
+	writel_relaxed(idx, base + cpu * PER_CPU_OFFSET +
+		       REG_PERFTBL_SEL_OFFSET);
+	return readl_relaxed(base + cpu * PER_CPU_OFFSET +
+			     REG_PERFTBL_RD_OFFSET);
+}
+
+static int virt_cpufreq_target(struct cpufreq_policy *policy,
+			       unsigned int target_freq,
+			       unsigned int relation)
+{
+	struct cpufreq_freqs freqs;
+	int ret = 0;
+
+	freqs.old = policy->cur;
+	freqs.new = target_freq;
+
+	cpufreq_freq_transition_begin(policy, &freqs);
+	ret = virt_cpufreq_set_perf(policy, target_freq);
+	cpufreq_freq_transition_end(policy, &freqs, ret != 0);
+
+	return ret;
+}
+
+static int virt_cpufreq_get_sharing_cpus(struct cpufreq_policy *policy)
+{
+	u32 cur_perf_domain, perf_domain;
+	struct device *cpu_dev;
+	int cpu;
+
+	cur_perf_domain = readl_relaxed(base + policy->cpu *
+					PER_CPU_OFFSET + REG_PERF_DOMAIN_OFFSET);
+
+	for_each_possible_cpu(cpu) {
+		cpu_dev = get_cpu_device(cpu);
+		if (!cpu_dev)
+			continue;
+
+		perf_domain = readl_relaxed(base + cpu *
+					    PER_CPU_OFFSET + REG_PERF_DOMAIN_OFFSET);
+
+		if (perf_domain == cur_perf_domain)
+			cpumask_set_cpu(cpu, policy->cpus);
+	}
+
+	return 0;
+}
+
+static int virt_cpufreq_get_freq_info(struct cpufreq_policy *policy)
+{
+	struct cpufreq_frequency_table *table;
+	u32 num_perftbl_entries, idx;
+
+	num_perftbl_entries = per_cpu(perftbl_num_entries, policy->cpu);
+
+	if (num_perftbl_entries == 1) {
+		policy->cpuinfo.min_freq = 1;
+		policy->cpuinfo.max_freq = virt_cpufreq_get_perftbl_entry(policy->cpu, 0);
+
+		policy->min = policy->cpuinfo.min_freq;
+		policy->max = policy->cpuinfo.max_freq;
+
+		policy->cur = policy->max;
+		return 0;
+	}
+
+	table = kcalloc(num_perftbl_entries + 1, sizeof(*table), GFP_KERNEL);
+	if (!table)
+		return -ENOMEM;
+
+	for (idx = 0; idx < num_perftbl_entries; idx++)
+		table[idx].frequency = virt_cpufreq_get_perftbl_entry(policy->cpu, idx);
+
+	table[idx].frequency = CPUFREQ_TABLE_END;
+	policy->freq_table = table;
+
+	return 0;
+}
+
+static int virt_cpufreq_cpu_init(struct cpufreq_policy *policy)
+{
+	struct device *cpu_dev;
+	int ret;
+
+	cpu_dev = get_cpu_device(policy->cpu);
+	if (!cpu_dev)
+		return -ENODEV;
+
+	ret = virt_cpufreq_get_freq_info(policy);
+	if (ret) {
+		dev_warn(cpu_dev, "failed to get cpufreq info\n");
+		return ret;
+	}
+
+	ret = virt_cpufreq_get_sharing_cpus(policy);
+	if (ret) {
+		dev_warn(cpu_dev, "failed to get sharing cpumask\n");
+		return ret;
+	}
+
+	/*
+	 * To simplify and improve latency of handling frequency requests on
+	 * the host side, this ensures that the vCPU thread triggering the MMIO
+	 * abort is the same thread whose performance constraints (Ex. uclamp
+	 * settings) need to be updated. This simplifies the VMM (Virtual
+	 * Machine Manager) having to find the correct vCPU thread and/or
+	 * facing permission issues when configuring other threads.
+	 */
+	policy->dvfs_possible_from_any_cpu = false;
+	policy->fast_switch_possible = true;
+
+	/*
+	 * Using the default SCALE_FREQ_SOURCE_CPUFREQ is insufficient since
+	 * the actual physical CPU frequency may not match requested frequency
+	 * from the vCPU thread due to frequency update latencies or other
+	 * inputs to the physical CPU frequency selection. This additional FIE
+	 * source allows for more accurate freq_scale updates and only takes
+	 * effect if another FIE source such as AMUs have not been registered.
+	 */
+	topology_set_scale_freq_source(&virt_sfd, policy->cpus);
+
+	return 0;
+}
+
+static void virt_cpufreq_cpu_exit(struct cpufreq_policy *policy)
+{
+	topology_clear_scale_freq_source(SCALE_FREQ_SOURCE_VIRT, policy->related_cpus);
+	kfree(policy->freq_table);
+}
+
+static int virt_cpufreq_online(struct cpufreq_policy *policy)
+{
+	/* Nothing to restore. */
+	return 0;
+}
+
+static int virt_cpufreq_offline(struct cpufreq_policy *policy)
+{
+	/* Dummy offline() to avoid exit() being called and freeing resources. */
+	return 0;
+}
+
+static int virt_cpufreq_verify_policy(struct cpufreq_policy_data *policy)
+{
+	if (policy->freq_table)
+		return cpufreq_frequency_table_verify(policy, policy->freq_table);
+
+	cpufreq_verify_within_cpu_limits(policy);
+	return 0;
+}
+
+static struct cpufreq_driver cpufreq_virt_driver = {
+	.name		= "virt-cpufreq",
+	.init		= virt_cpufreq_cpu_init,
+	.exit		= virt_cpufreq_cpu_exit,
+	.online         = virt_cpufreq_online,
+	.offline        = virt_cpufreq_offline,
+	.verify		= virt_cpufreq_verify_policy,
+	.target		= virt_cpufreq_target,
+	.fast_switch	= virt_cpufreq_fast_switch,
+	.attr		= cpufreq_generic_attr,
+};
+
+static int virt_cpufreq_driver_probe(struct platform_device *pdev)
+{
+	u32 num_perftbl_entries;
+	int ret, cpu;
+
+	base = devm_platform_ioremap_resource(pdev, 0);
+	if (IS_ERR(base))
+		return PTR_ERR(base);
+
+	for_each_possible_cpu(cpu) {
+		num_perftbl_entries = readl_relaxed(base + cpu * PER_CPU_OFFSET +
+						    REG_PERFTBL_LEN_OFFSET);
+
+		if (!num_perftbl_entries || num_perftbl_entries > PERFTBL_MAX_ENTRIES)
+			return -ENODEV;
+
+		per_cpu(perftbl_num_entries, cpu) = num_perftbl_entries;
+	}
+
+	ret = cpufreq_register_driver(&cpufreq_virt_driver);
+	if (ret) {
+		dev_err(&pdev->dev, "Virtual CPUFreq driver failed to register: %d\n", ret);
+		return ret;
+	}
+
+	dev_dbg(&pdev->dev, "Virtual CPUFreq driver initialized\n");
+	return 0;
+}
+
+static void virt_cpufreq_driver_remove(struct platform_device *pdev)
+{
+	cpufreq_unregister_driver(&cpufreq_virt_driver);
+}
+
+static const struct of_device_id virt_cpufreq_match[] = {
+	{ .compatible = "qemu,virtual-cpufreq", .data = NULL},
+	{}
+};
+MODULE_DEVICE_TABLE(of, virt_cpufreq_match);
+
+static struct platform_driver virt_cpufreq_driver = {
+	.probe = virt_cpufreq_driver_probe,
+	.remove = virt_cpufreq_driver_remove,
+	.driver = {
+		.name = "virt-cpufreq",
+		.of_match_table = virt_cpufreq_match,
+	},
+};
+
+static int __init virt_cpufreq_init(void)
+{
+	return platform_driver_register(&virt_cpufreq_driver);
+}
+postcore_initcall(virt_cpufreq_init);
+
+static void __exit virt_cpufreq_exit(void)
+{
+	platform_driver_unregister(&virt_cpufreq_driver);
+}
+module_exit(virt_cpufreq_exit);
+
+MODULE_DESCRIPTION("Virtual cpufreq driver");
+MODULE_LICENSE("GPL");
diff --git a/include/linux/arch_topology.h b/include/linux/arch_topology.h
index b721f360d759..d5d848849408 100644
--- a/include/linux/arch_topology.h
+++ b/include/linux/arch_topology.h
@@ -49,6 +49,7 @@ enum scale_freq_source {
 	SCALE_FREQ_SOURCE_CPUFREQ = 0,
 	SCALE_FREQ_SOURCE_ARCH,
 	SCALE_FREQ_SOURCE_CPPC,
+	SCALE_FREQ_SOURCE_VIRT,
 };
 
 struct scale_freq_data {
-- 
2.46.0.792.g87dc391469-goog

